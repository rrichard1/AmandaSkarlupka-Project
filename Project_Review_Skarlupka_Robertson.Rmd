# Overview

Title of project: Monoclonal Antibody Cross-Reactivity between Swine Influenza Hemagglutinins

Author of project: Amanda Skarlupka

## Background, Context and Motivation
How well is the context of the project described? Is a comprehensive background, including summary of previous/related work given? Is the project well placed into the context of existing work (including proper referencing of existing work). Is it clear why the project was undertaken and what new information it hopes to provide?

### Feedback and Comments

The context of the project is described with flu vaccine's effectiveness and efficacy, however there is no referencing of existing work (no citations). As someone who does not have a background in immunology, I was a little confused and would have liked more background information. Even just a paragraph or two summarizing previous work and placing more context would really help!

### Summary assessment
* some contextualization and motivation


## Question description
How well and clear are the question(s)/hypotheses the project aims to address described? Is it clear how the questions relate to the data?


### Feedback and Comments

The questions are clear and related to the data. I think it would be good to make a distinction on why the CA/09 antibodies are in comparison to the P1 antibodies again, as it was mentioned briefly in the introduction. 

### Summary assessment
* question/hypotheses mostly clear


## Data description
How well is the data overall described? Is the source provided? Is a codebook or other meta-information available that makes it clear what the data is? 

### Feedback and Comments

Data is well explained within the manuscript. Source of the data is provided and methods are really detailed on how the antibodies were produced. There are keys in the excel data sheet. I appreciated the summary table in the manuscript. 

### Summary assessment
* source and overall structure of data well explained


## Data wrangling and exploratory analysis
How well is the data cleaned/processed and explored? Are all steps reasonable and well explained? Are alternatives discussed and considered? Are meaningful exploratory results shown (e.g. in the supplementary materials)?

### Feedback and Comments

Data cleaning and processing was brief but efficient. Both the processing and analysis script were commented well and expalined each step. The analysis explored numerous different ways to display the data and the supplemental file showed many of these graphs. You did a great job looking at different reactivies and responses. 

### Summary assessment

* essentially no weaknesses in wrangling and exploratory component



## Appropriateness of Analysis
Were the analysis methods appropriate for the data? Was the analysis done properly? Were different components of the analysis (e.g. performance measure, variable selection, data pre-processing, model evaluation) done in the best way possible and explained well?

### Feedback and Comments

Different analyses were tried including: single predictor models, full logistic model, PCA analysis, and tree analysis. While the steps for the analyses were well documented and described, I also wanted to know what you thought about those results. You briefly mentioned about making the PCA stronger later on but I would like to know why your logistic model results tended to lead towards NC/09 HA. 

### Summary assessment
 
* defensible but not optimal analysis 

## Presentation
How well are results presented? Are tables and figures easy to read and understand? Are the main figures/tables publication level quality? 

### Feedback and Comments

I loved your graphs! They were so colorful and so well-labeled. However one of your graphs (Figure 12) mentions color in the legend but it is not present in the graph. 

### Summary assessment
* results are very well presented


## Discussion/Conclusions
Are the study findings properly discussed? Are strengths and limitations acknowledged? Are findings interpreted properly?

### Feedback and Comments

The study findings are properly summarized and discussed. The strengths and limitations are acknowledged and there is thoughtfulness on what may have gone wrong with one virus. My suggestion for this part is again link it to previous literature to place into context. 

### Summary assessment

* strong, complete and clear discussion


# Overall project content evaluation
Evaluate overall features of the project  by filling in the sections below.


## Structure
Is the project well structured? Are files in well labeled folders? Do files have reasonable names? Are all "junk" files not needed for analysis/reproduction removed? By just looking at files and folders, can you get an idea of how things fit together?

### Feedback and Comments

ReadMe files were clear in their instruction and all file names are reasonably titled. There are no junk files anywhere. Maybe just to make things clearer: separate your analysis code file into a subfolder for making the figures/tables and another subfolder for just analysis.

### Summary assessment

* well structured


## Documentation 
How well is the project documented? Are you able to understand each step of the whole analysis, each decision that was made, and each line of code? Is enough information provided as comments in code or as part of Rmd files? 

### Feedback and Comments

Code for all the scripts is well commented. Since this is a completely new field/project to me, knowing what you was doing the entire time was helpful. I especially appreciated the general comments the first line of the file indicating "This document contains the code for Table 2," etc.  

### Summary assessment

* fully and well documented



## Reproducibility
Are all results fully reproducible? Is documentation provided which clearly explains how to reproduce things, and does it work without the need for any manual intervention?

### Feedback and Comments

I ran into a few issues with running your code. The primary one was that using packages (ggbiplot and ggradar) from Github meant that I had to do a search and copy and paste those instructions in to get R to work. I suggest anything that isn't part of CRAN maybe put in the code to install? The other issue was that the "here" package wouldn't recognize arguments unless specifically called so I added in that when I could. The modeling.Rmd had an error code at line 130 and 209. I added some other comments in that file as well.


### Summary assessment

* small parts not reproducible or required manual intervention 



## Thoroughness
How thorough was the overall study? Were alternatives (e.g. different ways of processing the data or different models) considered? Were alternatives discussed? Were the questions/hypotheses fully and thoroughly addressed?

### Feedback and Comments

The study was very thorough with the data that was used. Different models and different ways to explain the data were used. In one script, code that didn't work for the data was commented out, but seeing that you attempted something and it didn't work means that you probably looked at several other ways as well. The questions were thoroughly addressed after reading through the manuscript. The supplemental material also showed many other alternatives of displaying the data.

### Summary assessment

* strong level of thorougness


## Further comments

Overall, I really enjoyed reading your manuscript! I found the study so fascinating! Because it was so interesting, I think just adding more in your introduction/discussion parts about the context of your work would make it more comprehensive. Your code is very clean and not at all lengthy and it was really easy to follow along with what you are doing. For your tree analysis, reducing the variables may give you a better tree, I struggled with mine until I limited the variables. 

Great job, Amanda!





